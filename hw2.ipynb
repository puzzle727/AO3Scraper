{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1c4rqHjAkg7BMih1pHHut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puzzle727/AO3Scraper/blob/master/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "0sh9DeLdwWXc",
        "outputId": "b65bacce-8d2b-489f-ff08-26c1b83aab6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a987118d-7095-4d11-a79b-d41c931fa3ed\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a987118d-7095-4d11-a79b-d41c931fa3ed\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dfout.csv to dfout.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded[\"dfout.csv\"]))"
      ],
      "metadata": {
        "id": "jfMXPhS01Hzu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "Q9hb4YzawgAr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#回归（采用数据）\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df1=pd.DataFrame(df,columns=['tea_space',\"drug\",\"baomo\",\"agr_money\"])\n",
        "#a.head()\n",
        "# 划分特征和目标变量\n",
        "X = df.drop('agr_money', axis=1)\n",
        "#X = X.drop('gu_space', axis=1)\n",
        "#X = X.drop('liangshi_space', axis=1)\n",
        "y = df['agr_money']\n",
        "# 划分训练集和测试集和验证集\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, random_state=23)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
      ],
      "metadata": {
        "id": "7Dq7Wm8N0ErT"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#数据的标准化处理\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQaHFh6X1rLe",
        "outputId": "165fda9b-34f1-45d4-ba89-3729d6143213"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_58 (Dense)            (None, 30)                390       \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 421 (1.64 KB)\n",
            "Trainable params: 421 (1.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=30)\n",
        "\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
        "history = model.fit(X_train, y_train, epochs=1200, validation_data=(X_valid, y_valid))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3d2t5pl1yBE",
        "outputId": "b8235272-0dea-4e49-f7ce-62707e9182fe"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "1/1 [==============================] - 2s 2s/step - loss: 904190.1875 - val_loss: 8915256320.0000\n",
            "Epoch 2/1200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 9819203584.0000 - val_loss: 41521340.0000\n",
            "Epoch 3/1200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 37500784.0000 - val_loss: 62175100.0000\n",
            "Epoch 4/1200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 152516000.0000 - val_loss: 1797539584.0000\n",
            "Epoch 5/1200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 3145862656.0000 - val_loss: 2952357376.0000\n",
            "Epoch 6/1200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4257356544.0000 - val_loss: 1311442048.0000\n",
            "Epoch 7/1200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 1290875264.0000 - val_loss: 507728352.0000\n",
            "Epoch 8/1200\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 326550080.0000 - val_loss: 63149120.0000\n",
            "Epoch 9/1200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 60632680.0000 - val_loss: 166998448.0000\n",
            "Epoch 10/1200\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 103901888.0000 - val_loss: 411945568.0000\n",
            "Epoch 11/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 235155488.0000 - val_loss: 385702144.0000\n",
            "Epoch 12/1200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 225491936.0000 - val_loss: 158446448.0000\n",
            "Epoch 13/1200\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 105933320.0000 - val_loss: 64531716.0000\n",
            "Epoch 14/1200\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 76057200.0000 - val_loss: 191402336.0000\n",
            "Epoch 15/1200\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 162431744.0000 - val_loss: 221524496.0000\n",
            "Epoch 16/1200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 143460560.0000 - val_loss: 115000104.0000\n",
            "Epoch 17/1200\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 63337492.0000 - val_loss: 30097550.0000\n",
            "Epoch 18/1200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 18398748.0000 - val_loss: 37510856.0000\n",
            "Epoch 19/1200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 43850336.0000 - val_loss: 77764872.0000\n",
            "Epoch 20/1200\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 79083368.0000 - val_loss: 81048776.0000\n",
            "Epoch 21/1200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 77528560.0000 - val_loss: 53391580.0000\n",
            "Epoch 22/1200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 65146264.0000 - val_loss: 27561054.0000\n",
            "Epoch 23/1200\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 51466104.0000 - val_loss: 13970549.0000\n",
            "Epoch 24/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 25005674.0000 - val_loss: 8269441.0000\n",
            "Epoch 25/1200\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 10966170.0000 - val_loss: 7039354.5000\n",
            "Epoch 26/1200\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 25027146.0000 - val_loss: 9996070.0000\n",
            "Epoch 27/1200\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 34874712.0000 - val_loss: 16856144.0000\n",
            "Epoch 28/1200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 27024838.0000 - val_loss: 22838958.0000\n",
            "Epoch 29/1200\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 23991960.0000 - val_loss: 20182222.0000\n",
            "Epoch 30/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 26060530.0000 - val_loss: 9855609.0000\n",
            "Epoch 31/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 16614205.0000 - val_loss: 2133236.5000\n",
            "Epoch 32/1200\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 5051115.0000 - val_loss: 1897540.1250\n",
            "Epoch 33/1200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4778684.5000 - val_loss: 5925310.5000\n",
            "Epoch 34/1200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 8280673.5000 - val_loss: 9826997.0000\n",
            "Epoch 35/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 7780685.5000 - val_loss: 11768767.0000\n",
            "Epoch 36/1200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 7528989.0000 - val_loss: 12025888.0000\n",
            "Epoch 37/1200\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 10076168.0000 - val_loss: 11390120.0000\n",
            "Epoch 38/1200\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 10023066.0000 - val_loss: 10295490.0000\n",
            "Epoch 39/1200\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 8278025.5000 - val_loss: 8856467.0000\n",
            "Epoch 40/1200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7386183.0000 - val_loss: 7310012.5000\n",
            "Epoch 41/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 4940683.5000 - val_loss: 5987718.5000\n",
            "Epoch 42/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3409038.0000 - val_loss: 5036896.5000\n",
            "Epoch 43/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2372685.2500 - val_loss: 4402503.0000\n",
            "Epoch 44/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1951037.0000 - val_loss: 3982938.7500\n",
            "Epoch 45/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1928374.2500 - val_loss: 3736811.2500\n",
            "Epoch 46/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 1695317.2500 - val_loss: 3624486.2500\n",
            "Epoch 47/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1387057.3750 - val_loss: 3583736.0000\n",
            "Epoch 48/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1404711.8750 - val_loss: 3519687.2500\n",
            "Epoch 49/1200\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 1530191.3750 - val_loss: 3388930.0000\n",
            "Epoch 50/1200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 1408433.7500 - val_loss: 3200570.0000\n",
            "Epoch 51/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1220412.7500 - val_loss: 2977314.5000\n",
            "Epoch 52/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1215126.3750 - val_loss: 2745741.2500\n",
            "Epoch 53/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1208323.3750 - val_loss: 2520614.7500\n",
            "Epoch 54/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1027032.6875 - val_loss: 2301945.7500\n",
            "Epoch 55/1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 848600.1250 - val_loss: 2085088.8750\n",
            "Epoch 56/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 815697.6250 - val_loss: 1868956.6250\n",
            "Epoch 57/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 770351.3750 - val_loss: 1660824.0000\n",
            "Epoch 58/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 624245.3750 - val_loss: 1471431.1250\n",
            "Epoch 59/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 522118.4375 - val_loss: 1309003.2500\n",
            "Epoch 60/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 518421.0625 - val_loss: 1174622.2500\n",
            "Epoch 61/1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 487707.1875 - val_loss: 1063697.1250\n",
            "Epoch 62/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 403294.8125 - val_loss: 970229.5625\n",
            "Epoch 63/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 369631.2812 - val_loss: 889632.3125\n",
            "Epoch 64/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 386603.3125 - val_loss: 819659.5000\n",
            "Epoch 65/1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 363983.0625 - val_loss: 759600.3750\n",
            "Epoch 66/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 315367.0938 - val_loss: 708726.9375\n",
            "Epoch 67/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 310642.3125 - val_loss: 665425.0625\n",
            "Epoch 68/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 323029.4688 - val_loss: 627573.6250\n",
            "Epoch 69/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 299136.6250 - val_loss: 593423.1875\n",
            "Epoch 70/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 267179.3125 - val_loss: 561991.3750\n",
            "Epoch 71/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 248487.8281 - val_loss: 532828.1875\n",
            "Epoch 72/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 230289.7031 - val_loss: 505716.2812\n",
            "Epoch 73/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 213591.1250 - val_loss: 480458.3438\n",
            "Epoch 74/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 190848.9688 - val_loss: 456686.5312\n",
            "Epoch 75/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 171851.7656 - val_loss: 433867.9062\n",
            "Epoch 76/1200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 163733.1562 - val_loss: 411468.9688\n",
            "Epoch 77/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 161656.3281 - val_loss: 389117.6562\n",
            "Epoch 78/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 156776.4688 - val_loss: 366720.7188\n",
            "Epoch 79/1200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 144434.0312 - val_loss: 344478.4062\n",
            "Epoch 80/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 127465.4141 - val_loss: 322780.6875\n",
            "Epoch 81/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 112601.5625 - val_loss: 302059.5000\n",
            "Epoch 82/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 104149.3906 - val_loss: 282660.4062\n",
            "Epoch 83/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 100803.5156 - val_loss: 264773.4375\n",
            "Epoch 84/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 97798.1875 - val_loss: 248432.6250\n",
            "Epoch 85/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 91650.5625 - val_loss: 233547.8906\n",
            "Epoch 86/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 82961.6094 - val_loss: 219950.0000\n",
            "Epoch 87/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 75166.9141 - val_loss: 207440.4688\n",
            "Epoch 88/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 70999.2188 - val_loss: 195836.2500\n",
            "Epoch 89/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 70146.6172 - val_loss: 185006.5781\n",
            "Epoch 90/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 69975.0078 - val_loss: 174891.7969\n",
            "Epoch 91/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 68175.2891 - val_loss: 165493.0312\n",
            "Epoch 92/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 64669.0820 - val_loss: 156840.7188\n",
            "Epoch 93/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 61202.0000 - val_loss: 148955.3594\n",
            "Epoch 94/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 59378.3555 - val_loss: 141822.6406\n",
            "Epoch 95/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 59171.9688 - val_loss: 135391.5156\n",
            "Epoch 96/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 59198.3867 - val_loss: 129591.3750\n",
            "Epoch 97/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 58130.3438 - val_loss: 124348.0469\n",
            "Epoch 98/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 55900.6641 - val_loss: 119603.2656\n",
            "Epoch 99/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 53524.7266 - val_loss: 115320.0859\n",
            "Epoch 100/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 51968.3203 - val_loss: 111480.7344\n",
            "Epoch 101/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 51274.3633 - val_loss: 108079.9141\n",
            "Epoch 102/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 50700.2422 - val_loss: 105117.1328\n",
            "Epoch 103/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 49566.0234 - val_loss: 102588.2656\n",
            "Epoch 104/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 47899.5586 - val_loss: 100475.4609\n",
            "Epoch 105/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 46305.2188 - val_loss: 98744.5000\n",
            "Epoch 106/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 45307.4883 - val_loss: 97345.3047\n",
            "Epoch 107/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 44877.8672 - val_loss: 96220.3984\n",
            "Epoch 108/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 44563.0547 - val_loss: 95315.5391\n",
            "Epoch 109/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 43990.8516 - val_loss: 94586.1172\n",
            "Epoch 110/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 43207.0430 - val_loss: 93999.4922\n",
            "Epoch 111/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 42548.6133 - val_loss: 93531.8203\n",
            "Epoch 112/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 42254.6016 - val_loss: 93136.6172\n",
            "Epoch 113/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 42237.1250 - val_loss: 92764.5625\n",
            "Epoch 114/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 42209.4492 - val_loss: 92447.0859\n",
            "Epoch 115/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 41986.9453 - val_loss: 92158.1953\n",
            "Epoch 116/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 41637.3984 - val_loss: 91852.2578\n",
            "Epoch 117/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 41358.0859 - val_loss: 91521.5156\n",
            "Epoch 118/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 41248.1484 - val_loss: 91146.3125\n",
            "Epoch 119/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 41219.9141 - val_loss: 90716.6953\n",
            "Epoch 120/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 41113.9297 - val_loss: 90232.5781\n",
            "Epoch 121/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 40868.7500 - val_loss: 89703.3984\n",
            "Epoch 122/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 40564.1797 - val_loss: 89143.8984\n",
            "Epoch 123/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 40316.6250 - val_loss: 88570.5391\n",
            "Epoch 124/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 40156.2266 - val_loss: 87998.3281\n",
            "Epoch 125/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 40014.0391 - val_loss: 87437.9844\n",
            "Epoch 126/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 39812.7852 - val_loss: 86896.5781\n",
            "Epoch 127/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 39550.8828 - val_loss: 86378.1094\n",
            "Epoch 128/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 39293.4805 - val_loss: 85884.3516\n",
            "Epoch 129/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 39096.0469 - val_loss: 85417.1328\n",
            "Epoch 130/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 38950.5273 - val_loss: 84979.2656\n",
            "Epoch 131/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 38806.3555 - val_loss: 84575.1797\n",
            "Epoch 132/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 38631.3672 - val_loss: 84210.4297\n",
            "Epoch 133/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 38442.2695 - val_loss: 83890.8047\n",
            "Epoch 134/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 38277.9766 - val_loss: 83620.7109\n",
            "Epoch 135/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 38153.5977 - val_loss: 83402.5703\n",
            "Epoch 136/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 38047.2812 - val_loss: 83236.3594\n",
            "Epoch 137/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37928.4688 - val_loss: 83119.7500\n",
            "Epoch 138/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37790.7031 - val_loss: 83049.0156\n",
            "Epoch 139/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 37652.5117 - val_loss: 83019.7344\n",
            "Epoch 140/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 37531.9453 - val_loss: 83027.2031\n",
            "Epoch 141/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 37426.0352 - val_loss: 83067.2969\n",
            "Epoch 142/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37316.8242 - val_loss: 83136.7656\n",
            "Epoch 143/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 37193.0938 - val_loss: 83233.0078\n",
            "Epoch 144/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 37060.8477 - val_loss: 83354.0156\n",
            "Epoch 145/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 36933.7344 - val_loss: 83497.6641\n",
            "Epoch 146/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 36816.7773 - val_loss: 83661.6953\n",
            "Epoch 147/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 36702.6680 - val_loss: 83840.6953\n",
            "Epoch 148/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 36582.2109 - val_loss: 84031.9766\n",
            "Epoch 149/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 36455.3789 - val_loss: 84233.4609\n",
            "Epoch 150/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 36329.7734 - val_loss: 84441.1250\n",
            "Epoch 151/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 36211.4922 - val_loss: 84651.6328\n",
            "Epoch 152/1200\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 36098.4609 - val_loss: 84861.3281\n",
            "Epoch 153/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 35984.6875 - val_loss: 85067.8203\n",
            "Epoch 154/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 35867.6172 - val_loss: 85269.5547\n",
            "Epoch 155/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 35750.5117 - val_loss: 85464.8594\n",
            "Epoch 156/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 35637.5938 - val_loss: 85653.2109\n",
            "Epoch 157/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 35529.0469 - val_loss: 85833.6719\n",
            "Epoch 158/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 35421.3789 - val_loss: 86005.4609\n",
            "Epoch 159/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 35311.8320 - val_loss: 86167.7969\n",
            "Epoch 160/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 35201.3711 - val_loss: 86319.7344\n",
            "Epoch 161/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 35092.6172 - val_loss: 86460.2500\n",
            "Epoch 162/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 34986.5859 - val_loss: 86589.0469\n",
            "Epoch 163/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 34881.4414 - val_loss: 86705.8750\n",
            "Epoch 164/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 34775.3672 - val_loss: 86811.3203\n",
            "Epoch 165/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 34668.4297 - val_loss: 86906.1094\n",
            "Epoch 166/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 34562.1094 - val_loss: 86991.6484\n",
            "Epoch 167/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 34457.5625 - val_loss: 87068.8359\n",
            "Epoch 168/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 34354.0703 - val_loss: 87139.2656\n",
            "Epoch 169/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 34250.4609 - val_loss: 87203.2656\n",
            "Epoch 170/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 34146.4453 - val_loss: 87261.6250\n",
            "Epoch 171/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 34043.0078 - val_loss: 87314.5703\n",
            "Epoch 172/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 33940.8359 - val_loss: 87362.3359\n",
            "Epoch 173/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 33839.7148 - val_loss: 87405.2344\n",
            "Epoch 174/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 33738.9141 - val_loss: 87444.0547\n",
            "Epoch 175/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 33638.1641 - val_loss: 87479.0781\n",
            "Epoch 176/1200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 33537.7969 - val_loss: 87511.2422\n",
            "Epoch 177/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 33438.3516 - val_loss: 87541.2109\n",
            "Epoch 178/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 33339.7227 - val_loss: 87569.5234\n",
            "Epoch 179/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 33241.4648 - val_loss: 87596.4141\n",
            "Epoch 180/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 33143.2578 - val_loss: 87621.8906\n",
            "Epoch 181/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 33045.3359 - val_loss: 87645.7500\n",
            "Epoch 182/1200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 32948.0195 - val_loss: 87667.4609\n",
            "Epoch 183/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 32851.2188 - val_loss: 87686.9297\n",
            "Epoch 184/1200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 32754.7812 - val_loss: 87703.8281\n",
            "Epoch 185/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 32658.4277 - val_loss: 87718.2109\n",
            "Epoch 186/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 32562.2910 - val_loss: 87730.2500\n",
            "Epoch 187/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 32466.6348 - val_loss: 87739.7891\n",
            "Epoch 188/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 32371.3555 - val_loss: 87746.7969\n",
            "Epoch 189/1200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 32276.4316 - val_loss: 87751.5234\n",
            "Epoch 190/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 32181.6836 - val_loss: 87753.3516\n",
            "Epoch 191/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 32087.2129 - val_loss: 87751.9297\n",
            "Epoch 192/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 31993.1133 - val_loss: 87747.1953\n",
            "Epoch 193/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 31899.4102 - val_loss: 87738.7656\n",
            "Epoch 194/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 31805.9941 - val_loss: 87726.2734\n",
            "Epoch 195/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 31712.8398 - val_loss: 87710.0156\n",
            "Epoch 196/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 31619.9492 - val_loss: 87689.8125\n",
            "Epoch 197/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 31527.3848 - val_loss: 87665.9297\n",
            "Epoch 198/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 31435.2188 - val_loss: 87638.4375\n",
            "Epoch 199/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 31343.2500 - val_loss: 87607.5156\n",
            "Epoch 200/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 31251.5723 - val_loss: 87573.0547\n",
            "Epoch 201/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 31160.1250 - val_loss: 87535.2500\n",
            "Epoch 202/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 31069.0098 - val_loss: 87493.8906\n",
            "Epoch 203/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 30978.1289 - val_loss: 87449.2109\n",
            "Epoch 204/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 30887.5371 - val_loss: 87401.1641\n",
            "Epoch 205/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 30797.1816 - val_loss: 87350.0859\n",
            "Epoch 206/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 30707.0625 - val_loss: 87296.2656\n",
            "Epoch 207/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 30617.2285 - val_loss: 87239.8984\n",
            "Epoch 208/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 30527.6445 - val_loss: 87181.1484\n",
            "Epoch 209/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 30438.3184 - val_loss: 87120.5078\n",
            "Epoch 210/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 30349.2090 - val_loss: 87057.8203\n",
            "Epoch 211/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 30260.3438 - val_loss: 86993.4453\n",
            "Epoch 212/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 30171.0938 - val_loss: 86927.5703\n",
            "Epoch 213/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 30074.2031 - val_loss: 86859.7344\n",
            "Epoch 214/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 29972.4160 - val_loss: 86790.2969\n",
            "Epoch 215/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 29866.3809 - val_loss: 86719.3359\n",
            "Epoch 216/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 29756.7754 - val_loss: 86646.8203\n",
            "Epoch 217/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 29644.1133 - val_loss: 86572.7500\n",
            "Epoch 218/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 29529.0664 - val_loss: 86497.6094\n",
            "Epoch 219/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 29412.1816 - val_loss: 86421.4375\n",
            "Epoch 220/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 29293.9004 - val_loss: 86344.2969\n",
            "Epoch 221/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 29174.6367 - val_loss: 86266.3594\n",
            "Epoch 222/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 29054.6504 - val_loss: 86187.3906\n",
            "Epoch 223/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 28934.4180 - val_loss: 86107.3516\n",
            "Epoch 224/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 28814.1250 - val_loss: 86026.2734\n",
            "Epoch 225/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 28694.1035 - val_loss: 85943.9609\n",
            "Epoch 226/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 28574.5000 - val_loss: 85860.5156\n",
            "Epoch 227/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 28455.5508 - val_loss: 85775.8906\n",
            "Epoch 228/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 28337.2969 - val_loss: 85690.1953\n",
            "Epoch 229/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 28220.0156 - val_loss: 85603.3906\n",
            "Epoch 230/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 28103.7441 - val_loss: 85515.7344\n",
            "Epoch 231/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27991.3809 - val_loss: 85427.0234\n",
            "Epoch 232/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 27887.0840 - val_loss: 85337.3750\n",
            "Epoch 233/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 27784.3848 - val_loss: 85246.7969\n",
            "Epoch 234/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 27683.2188 - val_loss: 85155.2266\n",
            "Epoch 235/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 27583.4883 - val_loss: 85062.6797\n",
            "Epoch 236/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 27485.2188 - val_loss: 84969.0078\n",
            "Epoch 237/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 27388.2715 - val_loss: 84874.4219\n",
            "Epoch 238/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 27292.5820 - val_loss: 84778.6875\n",
            "Epoch 239/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 27198.1133 - val_loss: 84682.0781\n",
            "Epoch 240/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 27104.7754 - val_loss: 84584.5625\n",
            "Epoch 241/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 27012.5898 - val_loss: 84486.3359\n",
            "Epoch 242/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26921.3945 - val_loss: 84387.3828\n",
            "Epoch 243/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 26831.2695 - val_loss: 84287.7656\n",
            "Epoch 244/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 26742.0781 - val_loss: 84187.3750\n",
            "Epoch 245/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 26653.8281 - val_loss: 84086.3125\n",
            "Epoch 246/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 26566.4336 - val_loss: 83984.6172\n",
            "Epoch 247/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 26479.9258 - val_loss: 83882.0703\n",
            "Epoch 248/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 26394.1719 - val_loss: 83778.8906\n",
            "Epoch 249/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 26309.1934 - val_loss: 83675.1719\n",
            "Epoch 250/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 26224.9590 - val_loss: 83570.8672\n",
            "Epoch 251/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 26141.4805 - val_loss: 83466.2344\n",
            "Epoch 252/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 26058.6914 - val_loss: 83361.1328\n",
            "Epoch 253/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 25976.5664 - val_loss: 83255.6797\n",
            "Epoch 254/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 25895.0293 - val_loss: 83149.8125\n",
            "Epoch 255/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 25814.1309 - val_loss: 83043.3984\n",
            "Epoch 256/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 25733.7617 - val_loss: 82936.5859\n",
            "Epoch 257/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25654.0195 - val_loss: 82829.4141\n",
            "Epoch 258/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 25574.7266 - val_loss: 82721.7344\n",
            "Epoch 259/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 25496.0215 - val_loss: 82613.9609\n",
            "Epoch 260/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 25417.7852 - val_loss: 82505.6797\n",
            "Epoch 261/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 25340.0293 - val_loss: 82397.0391\n",
            "Epoch 262/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 25262.7207 - val_loss: 82288.1719\n",
            "Epoch 263/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 25185.8887 - val_loss: 82179.0234\n",
            "Epoch 264/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 25109.4258 - val_loss: 82069.3906\n",
            "Epoch 265/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 25033.4434 - val_loss: 81959.4219\n",
            "Epoch 266/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 24957.8574 - val_loss: 81849.1484\n",
            "Epoch 267/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 24882.6621 - val_loss: 81738.4609\n",
            "Epoch 268/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 24808.0547 - val_loss: 81627.5078\n",
            "Epoch 269/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 24734.0527 - val_loss: 81516.2656\n",
            "Epoch 270/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 24660.4785 - val_loss: 81404.9609\n",
            "Epoch 271/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 24587.3184 - val_loss: 81293.4922\n",
            "Epoch 272/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 24514.5234 - val_loss: 81181.7031\n",
            "Epoch 273/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 24441.9883 - val_loss: 81069.9375\n",
            "Epoch 274/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 24368.8359 - val_loss: 80958.0234\n",
            "Epoch 275/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 24295.9277 - val_loss: 80846.1250\n",
            "Epoch 276/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 24223.2812 - val_loss: 80734.2500\n",
            "Epoch 277/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 24150.9023 - val_loss: 80622.2109\n",
            "Epoch 278/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 24078.7539 - val_loss: 80510.0547\n",
            "Epoch 279/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 24007.2227 - val_loss: 80397.7031\n",
            "Epoch 280/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23935.9355 - val_loss: 80285.1094\n",
            "Epoch 281/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 23864.9258 - val_loss: 80172.4844\n",
            "Epoch 282/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23794.1895 - val_loss: 80059.7109\n",
            "Epoch 283/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 23723.7539 - val_loss: 79946.9297\n",
            "Epoch 284/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 23653.5586 - val_loss: 79834.0156\n",
            "Epoch 285/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 23583.6348 - val_loss: 79721.1641\n",
            "Epoch 286/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 23513.9492 - val_loss: 79608.1719\n",
            "Epoch 287/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 23444.5254 - val_loss: 79494.9297\n",
            "Epoch 288/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 23375.5410 - val_loss: 79381.6328\n",
            "Epoch 289/1200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23306.8242 - val_loss: 79268.0547\n",
            "Epoch 290/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 23238.4492 - val_loss: 79154.4531\n",
            "Epoch 291/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 23170.2695 - val_loss: 79040.6797\n",
            "Epoch 292/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 23102.3574 - val_loss: 78926.8047\n",
            "Epoch 293/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 23034.6758 - val_loss: 78812.7578\n",
            "Epoch 294/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 22967.2637 - val_loss: 78698.7969\n",
            "Epoch 295/1200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 22900.0410 - val_loss: 78584.5703\n",
            "Epoch 296/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 22833.0488 - val_loss: 78470.2734\n",
            "Epoch 297/1200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 22766.3066 - val_loss: 78355.7344\n",
            "Epoch 298/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 22699.7715 - val_loss: 78240.9219\n",
            "Epoch 299/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 22633.4492 - val_loss: 78125.8047\n",
            "Epoch 300/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 22567.3203 - val_loss: 78010.6094\n",
            "Epoch 301/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 22501.4336 - val_loss: 77895.2500\n",
            "Epoch 302/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 22435.7305 - val_loss: 77779.5859\n",
            "Epoch 303/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 22370.2227 - val_loss: 77663.8828\n",
            "Epoch 304/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 22304.9062 - val_loss: 77547.8516\n",
            "Epoch 305/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 22239.8008 - val_loss: 77431.6250\n",
            "Epoch 306/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 22174.8555 - val_loss: 77315.1328\n",
            "Epoch 307/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 22110.1289 - val_loss: 77198.4453\n",
            "Epoch 308/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 22045.5664 - val_loss: 77081.4219\n",
            "Epoch 309/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 21981.1719 - val_loss: 76964.2656\n",
            "Epoch 310/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 21916.9805 - val_loss: 76846.7500\n",
            "Epoch 311/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 21852.9492 - val_loss: 76729.1250\n",
            "Epoch 312/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 21789.1055 - val_loss: 76611.3281\n",
            "Epoch 313/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 21725.4082 - val_loss: 76493.2734\n",
            "Epoch 314/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 21661.8711 - val_loss: 76375.0547\n",
            "Epoch 315/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 21598.5059 - val_loss: 76256.5156\n",
            "Epoch 316/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 21535.3145 - val_loss: 76137.9141\n",
            "Epoch 317/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 21472.2734 - val_loss: 76018.9609\n",
            "Epoch 318/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 21409.3867 - val_loss: 75899.9141\n",
            "Epoch 319/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 21346.6836 - val_loss: 75780.5859\n",
            "Epoch 320/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 21284.0977 - val_loss: 75661.2344\n",
            "Epoch 321/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 21221.6875 - val_loss: 75541.5859\n",
            "Epoch 322/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 21159.4023 - val_loss: 75421.9141\n",
            "Epoch 323/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 21097.2773 - val_loss: 75301.8828\n",
            "Epoch 324/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 21035.2930 - val_loss: 75181.7891\n",
            "Epoch 325/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 20973.4668 - val_loss: 75061.4922\n",
            "Epoch 326/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 20911.7891 - val_loss: 74941.0078\n",
            "Epoch 327/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 20850.2363 - val_loss: 74820.3750\n",
            "Epoch 328/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 20788.8379 - val_loss: 74699.6562\n",
            "Epoch 329/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 20727.5625 - val_loss: 74578.7344\n",
            "Epoch 330/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 20666.4082 - val_loss: 74457.5625\n",
            "Epoch 331/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 20605.3945 - val_loss: 74336.3516\n",
            "Epoch 332/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 20544.5488 - val_loss: 74214.9453\n",
            "Epoch 333/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 20483.8184 - val_loss: 74093.2656\n",
            "Epoch 334/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 20423.2090 - val_loss: 73971.4219\n",
            "Epoch 335/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 20362.7617 - val_loss: 73849.4844\n",
            "Epoch 336/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 20302.4258 - val_loss: 73727.3281\n",
            "Epoch 337/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 20242.2109 - val_loss: 73605.0234\n",
            "Epoch 338/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 20182.1074 - val_loss: 73482.5391\n",
            "Epoch 339/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 20122.1387 - val_loss: 73359.9453\n",
            "Epoch 340/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 20062.3164 - val_loss: 73237.1797\n",
            "Epoch 341/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 20002.5957 - val_loss: 73114.1875\n",
            "Epoch 342/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 19943.0195 - val_loss: 72991.0078\n",
            "Epoch 343/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 19883.5430 - val_loss: 72867.7500\n",
            "Epoch 344/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 19824.2168 - val_loss: 72744.1406\n",
            "Epoch 345/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 19764.9648 - val_loss: 72620.5000\n",
            "Epoch 346/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 19705.8770 - val_loss: 72496.5781\n",
            "Epoch 347/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 19646.8945 - val_loss: 72372.4922\n",
            "Epoch 348/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 19588.0195 - val_loss: 72248.2344\n",
            "Epoch 349/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 19529.2441 - val_loss: 72123.8750\n",
            "Epoch 350/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 19470.6211 - val_loss: 71999.1875\n",
            "Epoch 351/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 19412.1055 - val_loss: 71874.3672\n",
            "Epoch 352/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 19353.6934 - val_loss: 71749.3047\n",
            "Epoch 353/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 19295.4180 - val_loss: 71624.1641\n",
            "Epoch 354/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 19237.2109 - val_loss: 71498.7969\n",
            "Epoch 355/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 19179.1562 - val_loss: 71373.1641\n",
            "Epoch 356/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 19121.2227 - val_loss: 71247.2891\n",
            "Epoch 357/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 19063.3789 - val_loss: 71121.4062\n",
            "Epoch 358/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 19005.6406 - val_loss: 70995.1719\n",
            "Epoch 359/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 18948.4316 - val_loss: 70868.7500\n",
            "Epoch 360/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 18891.3457 - val_loss: 70742.2422\n",
            "Epoch 361/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18834.3516 - val_loss: 70615.6562\n",
            "Epoch 362/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 18777.4473 - val_loss: 70488.8359\n",
            "Epoch 363/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 18720.6523 - val_loss: 70361.6953\n",
            "Epoch 364/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 18663.9297 - val_loss: 70234.4375\n",
            "Epoch 365/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 18607.3359 - val_loss: 70106.9219\n",
            "Epoch 366/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 18550.8457 - val_loss: 69979.1094\n",
            "Epoch 367/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 18494.4121 - val_loss: 69851.1250\n",
            "Epoch 368/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18438.0859 - val_loss: 69723.0156\n",
            "Epoch 369/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 18381.8574 - val_loss: 69594.7578\n",
            "Epoch 370/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 18325.7305 - val_loss: 69466.2969\n",
            "Epoch 371/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 18269.6816 - val_loss: 69337.5547\n",
            "Epoch 372/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18213.7461 - val_loss: 69208.6875\n",
            "Epoch 373/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18157.9160 - val_loss: 69079.4141\n",
            "Epoch 374/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 18102.1875 - val_loss: 68950.0156\n",
            "Epoch 375/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 18046.5410 - val_loss: 68820.3047\n",
            "Epoch 376/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 17990.9492 - val_loss: 68690.5391\n",
            "Epoch 377/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 17935.4980 - val_loss: 68560.5234\n",
            "Epoch 378/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 17880.1523 - val_loss: 68430.2734\n",
            "Epoch 379/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 17824.8789 - val_loss: 68299.8984\n",
            "Epoch 380/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 17769.7148 - val_loss: 68169.1641\n",
            "Epoch 381/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 17714.6445 - val_loss: 68038.1484\n",
            "Epoch 382/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 17659.6719 - val_loss: 67906.8906\n",
            "Epoch 383/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 17604.7988 - val_loss: 67775.3984\n",
            "Epoch 384/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 17550.0156 - val_loss: 67643.7031\n",
            "Epoch 385/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 17495.3398 - val_loss: 67511.7500\n",
            "Epoch 386/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 17440.7461 - val_loss: 67379.5000\n",
            "Epoch 387/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 17386.2617 - val_loss: 67247.1562\n",
            "Epoch 388/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 17331.8789 - val_loss: 67114.4531\n",
            "Epoch 389/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17277.5938 - val_loss: 66981.4844\n",
            "Epoch 390/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 17223.4180 - val_loss: 66848.2188\n",
            "Epoch 391/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 17169.3047 - val_loss: 66714.6641\n",
            "Epoch 392/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 17115.3086 - val_loss: 66580.8516\n",
            "Epoch 393/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17061.4102 - val_loss: 66446.7891\n",
            "Epoch 394/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 17007.6094 - val_loss: 66312.5391\n",
            "Epoch 395/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 16953.9336 - val_loss: 66177.8984\n",
            "Epoch 396/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 16900.3164 - val_loss: 66043.0781\n",
            "Epoch 397/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 16846.8125 - val_loss: 65907.8984\n",
            "Epoch 398/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 16793.4199 - val_loss: 65772.4453\n",
            "Epoch 399/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 16740.1055 - val_loss: 65636.7500\n",
            "Epoch 400/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 16686.9141 - val_loss: 65500.7227\n",
            "Epoch 401/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 16633.8164 - val_loss: 65364.4727\n",
            "Epoch 402/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 16580.8105 - val_loss: 65227.9961\n",
            "Epoch 403/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 16527.9102 - val_loss: 65091.1797\n",
            "Epoch 404/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 16475.0938 - val_loss: 64954.1055\n",
            "Epoch 405/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 16422.4043 - val_loss: 64816.6758\n",
            "Epoch 406/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 16369.7910 - val_loss: 64679.1445\n",
            "Epoch 407/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 16317.3154 - val_loss: 64541.1055\n",
            "Epoch 408/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 16264.9160 - val_loss: 64402.9805\n",
            "Epoch 409/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 16212.6299 - val_loss: 64264.4453\n",
            "Epoch 410/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 16160.4316 - val_loss: 64125.6797\n",
            "Epoch 411/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 16108.3379 - val_loss: 63986.7070\n",
            "Epoch 412/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 16056.3535 - val_loss: 63847.4336\n",
            "Epoch 413/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 16004.4814 - val_loss: 63707.8125\n",
            "Epoch 414/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 15952.7109 - val_loss: 63568.0039\n",
            "Epoch 415/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 15901.0234 - val_loss: 63427.9180\n",
            "Epoch 416/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 15849.4590 - val_loss: 63287.5703\n",
            "Epoch 417/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 15797.9863 - val_loss: 63146.9805\n",
            "Epoch 418/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 15746.6113 - val_loss: 63006.0547\n",
            "Epoch 419/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 15695.3467 - val_loss: 62864.9688\n",
            "Epoch 420/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 15644.2129 - val_loss: 62723.5273\n",
            "Epoch 421/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 15593.1484 - val_loss: 62581.9648\n",
            "Epoch 422/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 15542.2080 - val_loss: 62440.0273\n",
            "Epoch 423/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 15491.3672 - val_loss: 62297.9297\n",
            "Epoch 424/1200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 15440.6406 - val_loss: 62155.5078\n",
            "Epoch 425/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 15390.0059 - val_loss: 62013.0195\n",
            "Epoch 426/1200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 15339.5059 - val_loss: 61870.0742\n",
            "Epoch 427/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 15289.0762 - val_loss: 61727.0195\n",
            "Epoch 428/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 15238.7627 - val_loss: 61583.6953\n",
            "Epoch 429/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 15188.5830 - val_loss: 61440.1797\n",
            "Epoch 430/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 15138.4873 - val_loss: 61296.3984\n",
            "Epoch 431/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 15088.5029 - val_loss: 61152.5078\n",
            "Epoch 432/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 15038.6250 - val_loss: 61008.2500\n",
            "Epoch 433/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 14988.8613 - val_loss: 60863.8633\n",
            "Epoch 434/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 14939.2158 - val_loss: 60719.2930\n",
            "Epoch 435/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 14889.6641 - val_loss: 60574.4180\n",
            "Epoch 436/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 14840.2217 - val_loss: 60429.4453\n",
            "Epoch 437/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 14790.8936 - val_loss: 60284.2148\n",
            "Epoch 438/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 14741.6699 - val_loss: 60138.8008\n",
            "Epoch 439/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 14692.5703 - val_loss: 59993.1758\n",
            "Epoch 440/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 14643.5732 - val_loss: 59847.4062\n",
            "Epoch 441/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 14594.6738 - val_loss: 59701.5195\n",
            "Epoch 442/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 14545.9141 - val_loss: 59555.3086\n",
            "Epoch 443/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 14497.2373 - val_loss: 59409.0078\n",
            "Epoch 444/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14448.6846 - val_loss: 59262.4648\n",
            "Epoch 445/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 14400.2373 - val_loss: 59115.9688\n",
            "Epoch 446/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14351.9189 - val_loss: 58969.1250\n",
            "Epoch 447/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 14303.7080 - val_loss: 58822.1523\n",
            "Epoch 448/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14255.5996 - val_loss: 58675.0898\n",
            "Epoch 449/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 14207.6064 - val_loss: 58527.8672\n",
            "Epoch 450/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 14159.7471 - val_loss: 58380.5742\n",
            "Epoch 451/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 14111.9824 - val_loss: 58232.9961\n",
            "Epoch 452/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 14064.3184 - val_loss: 58085.4102\n",
            "Epoch 453/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 14016.7734 - val_loss: 57937.6797\n",
            "Epoch 454/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13969.3730 - val_loss: 57789.9023\n",
            "Epoch 455/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13922.0596 - val_loss: 57641.8398\n",
            "Epoch 456/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13874.8652 - val_loss: 57493.8477\n",
            "Epoch 457/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 13827.7842 - val_loss: 57345.6797\n",
            "Epoch 458/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 13780.8301 - val_loss: 57197.3203\n",
            "Epoch 459/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 13733.9785 - val_loss: 57048.9805\n",
            "Epoch 460/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 13687.2783 - val_loss: 56900.5352\n",
            "Epoch 461/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13640.6436 - val_loss: 56752.0352\n",
            "Epoch 462/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 13594.1504 - val_loss: 56603.4062\n",
            "Epoch 463/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13547.7754 - val_loss: 56454.7227\n",
            "Epoch 464/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13501.5283 - val_loss: 56305.9727\n",
            "Epoch 465/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13455.3887 - val_loss: 56157.1992\n",
            "Epoch 466/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 13409.3457 - val_loss: 56008.4023\n",
            "Epoch 467/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 13363.4658 - val_loss: 55859.4570\n",
            "Epoch 468/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 13317.6660 - val_loss: 55710.5430\n",
            "Epoch 469/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 13271.9922 - val_loss: 55561.6289\n",
            "Epoch 470/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13226.4473 - val_loss: 55412.5625\n",
            "Epoch 471/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 13180.9971 - val_loss: 55263.5820\n",
            "Epoch 472/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13135.6934 - val_loss: 55114.5703\n",
            "Epoch 473/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 13090.4980 - val_loss: 54965.4570\n",
            "Epoch 474/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13045.4141 - val_loss: 54816.4062\n",
            "Epoch 475/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 13000.4551 - val_loss: 54667.3750\n",
            "Epoch 476/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12955.6172 - val_loss: 54518.2734\n",
            "Epoch 477/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 12910.8955 - val_loss: 54369.2227\n",
            "Epoch 478/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 12866.2783 - val_loss: 54220.1484\n",
            "Epoch 479/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 12821.8154 - val_loss: 54071.1484\n",
            "Epoch 480/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 12777.4561 - val_loss: 53922.1562\n",
            "Epoch 481/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12733.2139 - val_loss: 53773.1836\n",
            "Epoch 482/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 12689.0908 - val_loss: 53624.3398\n",
            "Epoch 483/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 12645.1035 - val_loss: 53475.3516\n",
            "Epoch 484/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 12601.2480 - val_loss: 53326.5742\n",
            "Epoch 485/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12557.4814 - val_loss: 53177.7930\n",
            "Epoch 486/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12513.8555 - val_loss: 53029.0664\n",
            "Epoch 487/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 12470.3516 - val_loss: 52880.3945\n",
            "Epoch 488/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12426.9551 - val_loss: 52731.8672\n",
            "Epoch 489/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 12383.7021 - val_loss: 52583.3516\n",
            "Epoch 490/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 12340.5859 - val_loss: 52434.9648\n",
            "Epoch 491/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 12297.5547 - val_loss: 52286.6680\n",
            "Epoch 492/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 12254.6846 - val_loss: 52138.3438\n",
            "Epoch 493/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12211.9102 - val_loss: 51990.2305\n",
            "Epoch 494/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 12169.2754 - val_loss: 51842.2773\n",
            "Epoch 495/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 12126.7793 - val_loss: 51694.3672\n",
            "Epoch 496/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12084.3848 - val_loss: 51546.5234\n",
            "Epoch 497/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12042.1123 - val_loss: 51398.8125\n",
            "Epoch 498/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 11999.9707 - val_loss: 51251.3047\n",
            "Epoch 499/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11957.9561 - val_loss: 51103.9414\n",
            "Epoch 500/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11916.0791 - val_loss: 50956.6484\n",
            "Epoch 501/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11874.3027 - val_loss: 50809.5898\n",
            "Epoch 502/1200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 11832.6914 - val_loss: 50662.5703\n",
            "Epoch 503/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11791.1670 - val_loss: 50515.7695\n",
            "Epoch 504/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11749.7910 - val_loss: 50369.1602\n",
            "Epoch 505/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11708.5332 - val_loss: 50222.7109\n",
            "Epoch 506/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 11667.4189 - val_loss: 50076.3750\n",
            "Epoch 507/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 11626.4014 - val_loss: 49930.3125\n",
            "Epoch 508/1200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 11585.5332 - val_loss: 49784.4297\n",
            "Epoch 509/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11544.7861 - val_loss: 49638.6992\n",
            "Epoch 510/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11504.1660 - val_loss: 49493.1680\n",
            "Epoch 511/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11463.6660 - val_loss: 49347.8047\n",
            "Epoch 512/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11423.3096 - val_loss: 49202.7305\n",
            "Epoch 513/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 11383.0645 - val_loss: 49057.8359\n",
            "Epoch 514/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 11342.9707 - val_loss: 48913.0977\n",
            "Epoch 515/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11303.0020 - val_loss: 48768.6797\n",
            "Epoch 516/1200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11263.1504 - val_loss: 48624.4922\n",
            "Epoch 517/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11223.4160 - val_loss: 48480.4805\n",
            "Epoch 518/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11183.8252 - val_loss: 48336.6797\n",
            "Epoch 519/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11144.3633 - val_loss: 48193.1953\n",
            "Epoch 520/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 11105.0254 - val_loss: 48049.9375\n",
            "Epoch 521/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 11065.8154 - val_loss: 47906.9648\n",
            "Epoch 522/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 11026.7441 - val_loss: 47764.1445\n",
            "Epoch 523/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 10987.7969 - val_loss: 47621.7148\n",
            "Epoch 524/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10948.9824 - val_loss: 47479.5000\n",
            "Epoch 525/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 10910.2998 - val_loss: 47337.5547\n",
            "Epoch 526/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 10871.7480 - val_loss: 47195.9375\n",
            "Epoch 527/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10833.3252 - val_loss: 47054.4922\n",
            "Epoch 528/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 10795.0273 - val_loss: 46913.4727\n",
            "Epoch 529/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10756.8701 - val_loss: 46772.6250\n",
            "Epoch 530/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10718.8340 - val_loss: 46632.1992\n",
            "Epoch 531/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10680.9326 - val_loss: 46492.0078\n",
            "Epoch 532/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10643.1621 - val_loss: 46352.1523\n",
            "Epoch 533/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 10605.5215 - val_loss: 46212.5547\n",
            "Epoch 534/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10568.0098 - val_loss: 46073.3047\n",
            "Epoch 535/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10530.6240 - val_loss: 45934.3477\n",
            "Epoch 536/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10493.3916 - val_loss: 45795.7695\n",
            "Epoch 537/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10456.2793 - val_loss: 45657.4453\n",
            "Epoch 538/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10419.2891 - val_loss: 45519.4805\n",
            "Epoch 539/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 10382.4512 - val_loss: 45381.8945\n",
            "Epoch 540/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 10345.7314 - val_loss: 45244.6797\n",
            "Epoch 541/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10309.1543 - val_loss: 45107.7227\n",
            "Epoch 542/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 10272.6963 - val_loss: 44971.1055\n",
            "Epoch 543/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10236.3730 - val_loss: 44834.9414\n",
            "Epoch 544/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10200.1875 - val_loss: 44699.0273\n",
            "Epoch 545/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 10164.1416 - val_loss: 44563.4922\n",
            "Epoch 546/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 10128.2148 - val_loss: 44428.3164\n",
            "Epoch 547/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 10092.4287 - val_loss: 44293.5352\n",
            "Epoch 548/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 10056.7783 - val_loss: 44159.1289\n",
            "Epoch 549/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 10021.2520 - val_loss: 44025.0820\n",
            "Epoch 550/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9985.8691 - val_loss: 43891.4375\n",
            "Epoch 551/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 9950.6035 - val_loss: 43758.1289\n",
            "Epoch 552/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 9915.4922 - val_loss: 43625.2148\n",
            "Epoch 553/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9880.5098 - val_loss: 43492.7109\n",
            "Epoch 554/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9845.6484 - val_loss: 43360.5820\n",
            "Epoch 555/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9810.9434 - val_loss: 43228.8203\n",
            "Epoch 556/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9776.3555 - val_loss: 43097.5039\n",
            "Epoch 557/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9741.8984 - val_loss: 42966.4961\n",
            "Epoch 558/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9707.5771 - val_loss: 42836.0352\n",
            "Epoch 559/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9673.4033 - val_loss: 42705.8008\n",
            "Epoch 560/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9639.3633 - val_loss: 42576.0703\n",
            "Epoch 561/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9605.4434 - val_loss: 42446.8047\n",
            "Epoch 562/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9571.6543 - val_loss: 42317.8945\n",
            "Epoch 563/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 9538.0156 - val_loss: 42189.3750\n",
            "Epoch 564/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9504.5117 - val_loss: 42061.3047\n",
            "Epoch 565/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9471.1152 - val_loss: 41933.5938\n",
            "Epoch 566/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9437.8965 - val_loss: 41806.3828\n",
            "Epoch 567/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 9404.7891 - val_loss: 41679.5938\n",
            "Epoch 568/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 9371.8154 - val_loss: 41553.2383\n",
            "Epoch 569/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 9338.9863 - val_loss: 41427.2500\n",
            "Epoch 570/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9306.2842 - val_loss: 41301.7305\n",
            "Epoch 571/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9273.7139 - val_loss: 41176.6484\n",
            "Epoch 572/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 9241.2920 - val_loss: 41051.9297\n",
            "Epoch 573/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9208.9990 - val_loss: 40927.7852\n",
            "Epoch 574/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9176.8525 - val_loss: 40804.0117\n",
            "Epoch 575/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9144.8135 - val_loss: 40680.7070\n",
            "Epoch 576/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9112.9258 - val_loss: 40557.8789\n",
            "Epoch 577/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9081.1895 - val_loss: 40435.3945\n",
            "Epoch 578/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9049.5527 - val_loss: 40313.3867\n",
            "Epoch 579/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9018.0752 - val_loss: 40191.8867\n",
            "Epoch 580/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8986.7363 - val_loss: 40070.8047\n",
            "Epoch 581/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8955.5381 - val_loss: 39950.1367\n",
            "Epoch 582/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8924.4561 - val_loss: 39830.0000\n",
            "Epoch 583/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8893.5156 - val_loss: 39710.2422\n",
            "Epoch 584/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8862.7002 - val_loss: 39590.9727\n",
            "Epoch 585/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8832.0488 - val_loss: 39472.1484\n",
            "Epoch 586/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8801.5098 - val_loss: 39353.8203\n",
            "Epoch 587/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 8771.1152 - val_loss: 39235.9102\n",
            "Epoch 588/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8740.8516 - val_loss: 39118.4727\n",
            "Epoch 589/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8710.7402 - val_loss: 39001.5664\n",
            "Epoch 590/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8680.7344 - val_loss: 38885.0352\n",
            "Epoch 591/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8650.8887 - val_loss: 38769.0273\n",
            "Epoch 592/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8621.1738 - val_loss: 38653.4805\n",
            "Epoch 593/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8591.5967 - val_loss: 38538.3320\n",
            "Epoch 594/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8562.1387 - val_loss: 38423.7266\n",
            "Epoch 595/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8532.8291 - val_loss: 38309.5391\n",
            "Epoch 596/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8504.0869 - val_loss: 38195.4375\n",
            "Epoch 597/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8475.6484 - val_loss: 38081.5273\n",
            "Epoch 598/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8447.3809 - val_loss: 37967.9336\n",
            "Epoch 599/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8419.2754 - val_loss: 37854.8203\n",
            "Epoch 600/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8391.3496 - val_loss: 37742.1758\n",
            "Epoch 601/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8363.5918 - val_loss: 37630.3008\n",
            "Epoch 602/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8335.9736 - val_loss: 37519.1758\n",
            "Epoch 603/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8308.5254 - val_loss: 37408.8750\n",
            "Epoch 604/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8281.2402 - val_loss: 37299.3828\n",
            "Epoch 605/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 8254.1074 - val_loss: 37190.9258\n",
            "Epoch 606/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 8227.1309 - val_loss: 37083.3828\n",
            "Epoch 607/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8200.3105 - val_loss: 36976.8164\n",
            "Epoch 608/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8173.6338 - val_loss: 36871.4453\n",
            "Epoch 609/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8147.1201 - val_loss: 36767.0508\n",
            "Epoch 610/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8120.7549 - val_loss: 36663.6992\n",
            "Epoch 611/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8094.5273 - val_loss: 36561.4258\n",
            "Epoch 612/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8068.4492 - val_loss: 36460.2695\n",
            "Epoch 613/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 8042.5273 - val_loss: 36360.2383\n",
            "Epoch 614/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8016.7500 - val_loss: 36261.2227\n",
            "Epoch 615/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7991.1025 - val_loss: 36163.2539\n",
            "Epoch 616/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 7965.6104 - val_loss: 36066.3125\n",
            "Epoch 617/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7940.2617 - val_loss: 35970.4727\n",
            "Epoch 618/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7915.0649 - val_loss: 35875.5469\n",
            "Epoch 619/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7889.9893 - val_loss: 35781.5742\n",
            "Epoch 620/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7865.0703 - val_loss: 35688.6367\n",
            "Epoch 621/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 7840.3018 - val_loss: 35596.5469\n",
            "Epoch 622/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7815.6499 - val_loss: 35505.3867\n",
            "Epoch 623/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7791.1602 - val_loss: 35415.1133\n",
            "Epoch 624/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7766.8022 - val_loss: 35325.6953\n",
            "Epoch 625/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 7742.5845 - val_loss: 35237.0508\n",
            "Epoch 626/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7718.5127 - val_loss: 35149.1172\n",
            "Epoch 627/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7694.5757 - val_loss: 35061.9727\n",
            "Epoch 628/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7670.7764 - val_loss: 34975.6172\n",
            "Epoch 629/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7647.1196 - val_loss: 34889.8672\n",
            "Epoch 630/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7623.5850 - val_loss: 34804.8633\n",
            "Epoch 631/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7600.2070 - val_loss: 34720.4727\n",
            "Epoch 632/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 7576.9546 - val_loss: 34636.6406\n",
            "Epoch 633/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7553.8467 - val_loss: 34553.5625\n",
            "Epoch 634/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7530.8774 - val_loss: 34470.9609\n",
            "Epoch 635/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7508.0327 - val_loss: 34388.8477\n",
            "Epoch 636/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7485.3350 - val_loss: 34307.3477\n",
            "Epoch 637/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7462.7734 - val_loss: 34226.3633\n",
            "Epoch 638/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7440.4399 - val_loss: 34146.3633\n",
            "Epoch 639/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 7418.1265 - val_loss: 34067.3711\n",
            "Epoch 640/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 7395.9077 - val_loss: 33988.6523\n",
            "Epoch 641/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 7373.8853 - val_loss: 33910.2891\n",
            "Epoch 642/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 7351.9922 - val_loss: 33832.1680\n",
            "Epoch 643/1200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7330.2461 - val_loss: 33754.2812\n",
            "Epoch 644/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 7308.6118 - val_loss: 33676.7695\n",
            "Epoch 645/1200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7287.1240 - val_loss: 33599.4102\n",
            "Epoch 646/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 7265.7720 - val_loss: 33522.3477\n",
            "Epoch 647/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 7244.5361 - val_loss: 33445.5195\n",
            "Epoch 648/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 7223.4258 - val_loss: 33368.9844\n",
            "Epoch 649/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 7202.4639 - val_loss: 33292.7188\n",
            "Epoch 650/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 7181.6182 - val_loss: 33216.8711\n",
            "Epoch 651/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 7160.9180 - val_loss: 33141.2773\n",
            "Epoch 652/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7140.3374 - val_loss: 33065.9570\n",
            "Epoch 653/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 7119.8765 - val_loss: 32991.1016\n",
            "Epoch 654/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 7099.5547 - val_loss: 32916.5078\n",
            "Epoch 655/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 7079.3530 - val_loss: 32842.3594\n",
            "Epoch 656/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 7059.3008 - val_loss: 32768.4766\n",
            "Epoch 657/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7039.3623 - val_loss: 32694.9668\n",
            "Epoch 658/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 7019.5562 - val_loss: 32621.9492\n",
            "Epoch 659/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6999.8721 - val_loss: 32549.1699\n",
            "Epoch 660/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6980.3096 - val_loss: 32476.8555\n",
            "Epoch 661/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6960.8818 - val_loss: 32404.9023\n",
            "Epoch 662/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6941.5767 - val_loss: 32333.3125\n",
            "Epoch 663/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6922.3955 - val_loss: 32262.1270\n",
            "Epoch 664/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6903.3423 - val_loss: 32191.2598\n",
            "Epoch 665/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 6884.4180 - val_loss: 32120.8613\n",
            "Epoch 666/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 6865.6079 - val_loss: 32050.8438\n",
            "Epoch 667/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 6846.9248 - val_loss: 31981.1660\n",
            "Epoch 668/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 6828.3735 - val_loss: 31911.8965\n",
            "Epoch 669/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6809.9375 - val_loss: 31843.0215\n",
            "Epoch 670/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 6791.6250 - val_loss: 31774.6035\n",
            "Epoch 671/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6773.4336 - val_loss: 31706.6055\n",
            "Epoch 672/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6755.3579 - val_loss: 31638.9785\n",
            "Epoch 673/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 6737.4180 - val_loss: 31571.7852\n",
            "Epoch 674/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6719.5728 - val_loss: 31505.0410\n",
            "Epoch 675/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 6701.8711 - val_loss: 31438.6992\n",
            "Epoch 676/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6684.2773 - val_loss: 31372.7090\n",
            "Epoch 677/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 6666.8057 - val_loss: 31307.2051\n",
            "Epoch 678/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 6649.4517 - val_loss: 31242.0898\n",
            "Epoch 679/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 6632.2173 - val_loss: 31177.3652\n",
            "Epoch 680/1200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 6615.0977 - val_loss: 31113.0449\n",
            "Epoch 681/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6598.1006 - val_loss: 31049.0840\n",
            "Epoch 682/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 6581.2095 - val_loss: 30985.5996\n",
            "Epoch 683/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 6564.4351 - val_loss: 30922.3887\n",
            "Epoch 684/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6547.7783 - val_loss: 30859.5840\n",
            "Epoch 685/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 6531.2373 - val_loss: 30797.2012\n",
            "Epoch 686/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6514.8110 - val_loss: 30735.1035\n",
            "Epoch 687/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6498.4990 - val_loss: 30673.3477\n",
            "Epoch 688/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6482.2861 - val_loss: 30612.0762\n",
            "Epoch 689/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6466.1973 - val_loss: 30551.0176\n",
            "Epoch 690/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6450.2139 - val_loss: 30490.3340\n",
            "Epoch 691/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6434.3423 - val_loss: 30429.9961\n",
            "Epoch 692/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6418.5869 - val_loss: 30370.0039\n",
            "Epoch 693/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6402.9312 - val_loss: 30310.3867\n",
            "Epoch 694/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6387.3916 - val_loss: 30251.0312\n",
            "Epoch 695/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6371.9575 - val_loss: 30192.0723\n",
            "Epoch 696/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6356.6348 - val_loss: 30133.3125\n",
            "Epoch 697/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6341.4150 - val_loss: 30074.9688\n",
            "Epoch 698/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6326.3008 - val_loss: 30016.9160\n",
            "Epoch 699/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6311.2915 - val_loss: 29959.2051\n",
            "Epoch 700/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6296.3896 - val_loss: 29901.7090\n",
            "Epoch 701/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6281.5952 - val_loss: 29844.6152\n",
            "Epoch 702/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6266.8960 - val_loss: 29787.8379\n",
            "Epoch 703/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 6252.3125 - val_loss: 29731.3027\n",
            "Epoch 704/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6237.8218 - val_loss: 29675.0840\n",
            "Epoch 705/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6223.4346 - val_loss: 29619.1191\n",
            "Epoch 706/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6209.1455 - val_loss: 29563.4629\n",
            "Epoch 707/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6194.9673 - val_loss: 29508.0879\n",
            "Epoch 708/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6180.8745 - val_loss: 29452.9941\n",
            "Epoch 709/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6166.8901 - val_loss: 29398.2285\n",
            "Epoch 710/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6153.0142 - val_loss: 29343.6816\n",
            "Epoch 711/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6139.2271 - val_loss: 29289.4082\n",
            "Epoch 712/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6125.5342 - val_loss: 29235.3965\n",
            "Epoch 713/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6111.9385 - val_loss: 29181.6855\n",
            "Epoch 714/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6098.4463 - val_loss: 29128.2402\n",
            "Epoch 715/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6085.0459 - val_loss: 29075.0137\n",
            "Epoch 716/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6071.7354 - val_loss: 29022.1387\n",
            "Epoch 717/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6058.5195 - val_loss: 28969.4355\n",
            "Epoch 718/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 6045.3960 - val_loss: 28917.0469\n",
            "Epoch 719/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6032.3740 - val_loss: 28864.9082\n",
            "Epoch 720/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6019.4443 - val_loss: 28813.0312\n",
            "Epoch 721/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6006.5991 - val_loss: 28761.4199\n",
            "Epoch 722/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5993.8501 - val_loss: 28710.0293\n",
            "Epoch 723/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5981.1846 - val_loss: 28658.9121\n",
            "Epoch 724/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5968.6147 - val_loss: 28607.9824\n",
            "Epoch 725/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5956.1304 - val_loss: 28557.4160\n",
            "Epoch 726/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5943.7314 - val_loss: 28507.0059\n",
            "Epoch 727/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5931.4248 - val_loss: 28456.8965\n",
            "Epoch 728/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5919.2070 - val_loss: 28407.0176\n",
            "Epoch 729/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5907.0718 - val_loss: 28357.3555\n",
            "Epoch 730/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5895.0259 - val_loss: 28308.0312\n",
            "Epoch 731/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5883.0625 - val_loss: 28258.8594\n",
            "Epoch 732/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5871.1826 - val_loss: 28209.9492\n",
            "Epoch 733/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5859.3853 - val_loss: 28161.2715\n",
            "Epoch 734/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5847.6709 - val_loss: 28112.8262\n",
            "Epoch 735/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5836.0415 - val_loss: 28064.6074\n",
            "Epoch 736/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5824.4971 - val_loss: 28016.6523\n",
            "Epoch 737/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5813.0244 - val_loss: 27968.8945\n",
            "Epoch 738/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5801.6372 - val_loss: 27921.2930\n",
            "Epoch 739/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5790.3350 - val_loss: 27874.0566\n",
            "Epoch 740/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5779.0991 - val_loss: 27826.9707\n",
            "Epoch 741/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5767.9595 - val_loss: 27780.1133\n",
            "Epoch 742/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 5756.8779 - val_loss: 27733.4492\n",
            "Epoch 743/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5745.8828 - val_loss: 27687.0605\n",
            "Epoch 744/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5734.9634 - val_loss: 27640.8652\n",
            "Epoch 745/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5724.1265 - val_loss: 27594.9043\n",
            "Epoch 746/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5713.3506 - val_loss: 27549.1191\n",
            "Epoch 747/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5702.6709 - val_loss: 27503.6094\n",
            "Epoch 748/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5692.0435 - val_loss: 27458.3574\n",
            "Epoch 749/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5681.4971 - val_loss: 27413.1660\n",
            "Epoch 750/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5671.0278 - val_loss: 27368.2363\n",
            "Epoch 751/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5660.6211 - val_loss: 27323.5410\n",
            "Epoch 752/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5650.2969 - val_loss: 27279.0371\n",
            "Epoch 753/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5640.0381 - val_loss: 27234.7383\n",
            "Epoch 754/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5629.8516 - val_loss: 27190.6504\n",
            "Epoch 755/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5619.7241 - val_loss: 27146.7617\n",
            "Epoch 756/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5609.6714 - val_loss: 27103.0312\n",
            "Epoch 757/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5599.6929 - val_loss: 27059.5137\n",
            "Epoch 758/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5589.7842 - val_loss: 27016.1777\n",
            "Epoch 759/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 5579.9297 - val_loss: 26973.1113\n",
            "Epoch 760/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5570.1548 - val_loss: 26930.1445\n",
            "Epoch 761/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5560.4307 - val_loss: 26887.4102\n",
            "Epoch 762/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5550.7803 - val_loss: 26844.7812\n",
            "Epoch 763/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5541.1982 - val_loss: 26802.4551\n",
            "Epoch 764/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5531.6704 - val_loss: 26760.2344\n",
            "Epoch 765/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5522.2188 - val_loss: 26718.2285\n",
            "Epoch 766/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5512.8188 - val_loss: 26676.4199\n",
            "Epoch 767/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5503.4854 - val_loss: 26634.7461\n",
            "Epoch 768/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5494.2061 - val_loss: 26593.2949\n",
            "Epoch 769/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5485.0005 - val_loss: 26552.0273\n",
            "Epoch 770/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 5475.8447 - val_loss: 26510.9277\n",
            "Epoch 771/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5466.7568 - val_loss: 26469.9551\n",
            "Epoch 772/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 5457.7212 - val_loss: 26429.1445\n",
            "Epoch 773/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5448.7500 - val_loss: 26388.5449\n",
            "Epoch 774/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5439.8232 - val_loss: 26348.0762\n",
            "Epoch 775/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5430.9668 - val_loss: 26307.7656\n",
            "Epoch 776/1200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 5422.1675 - val_loss: 26267.7129\n",
            "Epoch 777/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5413.4238 - val_loss: 26227.7383\n",
            "Epoch 778/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 5404.7261 - val_loss: 26187.9551\n",
            "Epoch 779/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5396.0903 - val_loss: 26148.3496\n",
            "Epoch 780/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5387.5156 - val_loss: 26108.8691\n",
            "Epoch 781/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5378.9878 - val_loss: 26069.5508\n",
            "Epoch 782/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5370.5137 - val_loss: 26030.4316\n",
            "Epoch 783/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5362.0869 - val_loss: 25991.4844\n",
            "Epoch 784/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5353.7236 - val_loss: 25952.6230\n",
            "Epoch 785/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5345.4097 - val_loss: 25913.9316\n",
            "Epoch 786/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5337.1401 - val_loss: 25875.4082\n",
            "Epoch 787/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5328.9258 - val_loss: 25836.9961\n",
            "Epoch 788/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5320.7627 - val_loss: 25798.7305\n",
            "Epoch 789/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5312.6455 - val_loss: 25760.6777\n",
            "Epoch 790/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5304.5791 - val_loss: 25722.7227\n",
            "Epoch 791/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5296.5635 - val_loss: 25684.9551\n",
            "Epoch 792/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5288.5947 - val_loss: 25647.2559\n",
            "Epoch 793/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 5280.6772 - val_loss: 25609.7539\n",
            "Epoch 794/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5272.7979 - val_loss: 25572.3887\n",
            "Epoch 795/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5264.9697 - val_loss: 25535.1582\n",
            "Epoch 796/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5257.1865 - val_loss: 25498.0469\n",
            "Epoch 797/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5249.4502 - val_loss: 25461.0898\n",
            "Epoch 798/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5241.7588 - val_loss: 25424.2676\n",
            "Epoch 799/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5234.1050 - val_loss: 25387.5801\n",
            "Epoch 800/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5226.5088 - val_loss: 25350.9941\n",
            "Epoch 801/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5218.9482 - val_loss: 25314.5527\n",
            "Epoch 802/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 5211.4307 - val_loss: 25278.3008\n",
            "Epoch 803/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 5203.9595 - val_loss: 25242.1426\n",
            "Epoch 804/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5196.5244 - val_loss: 25206.1133\n",
            "Epoch 805/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5189.1338 - val_loss: 25170.2090\n",
            "Epoch 806/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 5181.7812 - val_loss: 25134.4199\n",
            "Epoch 807/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5174.4741 - val_loss: 25098.8027\n",
            "Epoch 808/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5167.2085 - val_loss: 25063.2520\n",
            "Epoch 809/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 5159.9800 - val_loss: 25027.8574\n",
            "Epoch 810/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5152.7861 - val_loss: 24992.6113\n",
            "Epoch 811/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 5145.6357 - val_loss: 24957.4551\n",
            "Epoch 812/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5138.5283 - val_loss: 24922.4160\n",
            "Epoch 813/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5131.4473 - val_loss: 24887.4980\n",
            "Epoch 814/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5124.4116 - val_loss: 24852.7656\n",
            "Epoch 815/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5117.4165 - val_loss: 24818.0781\n",
            "Epoch 816/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5110.4492 - val_loss: 24783.4902\n",
            "Epoch 817/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5103.5259 - val_loss: 24749.0273\n",
            "Epoch 818/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5096.6353 - val_loss: 24714.7227\n",
            "Epoch 819/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5089.7798 - val_loss: 24680.5684\n",
            "Epoch 820/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5082.9595 - val_loss: 24646.4512\n",
            "Epoch 821/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5076.1753 - val_loss: 24612.4785\n",
            "Epoch 822/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5069.4233 - val_loss: 24578.6152\n",
            "Epoch 823/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5062.7036 - val_loss: 24544.8750\n",
            "Epoch 824/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5056.0156 - val_loss: 24511.1973\n",
            "Epoch 825/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5049.3657 - val_loss: 24477.7012\n",
            "Epoch 826/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5042.7446 - val_loss: 24444.2676\n",
            "Epoch 827/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 5036.1611 - val_loss: 24410.9062\n",
            "Epoch 828/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5029.6006 - val_loss: 24377.7188\n",
            "Epoch 829/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 5023.0820 - val_loss: 24344.6738\n",
            "Epoch 830/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5016.5820 - val_loss: 24311.6504\n",
            "Epoch 831/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5010.1201 - val_loss: 24278.7520\n",
            "Epoch 832/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5003.6885 - val_loss: 24245.9668\n",
            "Epoch 833/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4997.2866 - val_loss: 24213.2871\n",
            "Epoch 834/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4990.9146 - val_loss: 24180.6602\n",
            "Epoch 835/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4984.5693 - val_loss: 24148.1582\n",
            "Epoch 836/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4978.2500 - val_loss: 24115.7988\n",
            "Epoch 837/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4971.9634 - val_loss: 24083.4902\n",
            "Epoch 838/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4965.7090 - val_loss: 24051.3105\n",
            "Epoch 839/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4959.4736 - val_loss: 24019.2539\n",
            "Epoch 840/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4953.2695 - val_loss: 23987.2324\n",
            "Epoch 841/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4947.0947 - val_loss: 23955.3223\n",
            "Epoch 842/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4940.9438 - val_loss: 23923.5586\n",
            "Epoch 843/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4934.8179 - val_loss: 23891.8438\n",
            "Epoch 844/1200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 4928.7236 - val_loss: 23860.2305\n",
            "Epoch 845/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4922.6460 - val_loss: 23828.7383\n",
            "Epoch 846/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4916.6045 - val_loss: 23797.3164\n",
            "Epoch 847/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4910.5801 - val_loss: 23765.9590\n",
            "Epoch 848/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4904.5796 - val_loss: 23734.7285\n",
            "Epoch 849/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4898.6099 - val_loss: 23703.6035\n",
            "Epoch 850/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4892.6606 - val_loss: 23672.5039\n",
            "Epoch 851/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4886.7275 - val_loss: 23641.5645\n",
            "Epoch 852/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4880.8311 - val_loss: 23610.6934\n",
            "Epoch 853/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4874.9565 - val_loss: 23579.9023\n",
            "Epoch 854/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4869.1006 - val_loss: 23549.2207\n",
            "Epoch 855/1200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 4863.2642 - val_loss: 23518.6211\n",
            "Epoch 856/1200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 4857.4580 - val_loss: 23488.0723\n",
            "Epoch 857/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4851.6694 - val_loss: 23457.6543\n",
            "Epoch 858/1200\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 4845.8970 - val_loss: 23427.3379\n",
            "Epoch 859/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 4840.1514 - val_loss: 23397.0605\n",
            "Epoch 860/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4834.4297 - val_loss: 23366.8887\n",
            "Epoch 861/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 4828.7256 - val_loss: 23336.8223\n",
            "Epoch 862/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 4823.0386 - val_loss: 23306.7715\n",
            "Epoch 863/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4817.3794 - val_loss: 23276.8730\n",
            "Epoch 864/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4811.7378 - val_loss: 23247.0371\n",
            "Epoch 865/1200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4806.1138 - val_loss: 23217.3086\n",
            "Epoch 866/1200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4800.5117 - val_loss: 23187.6113\n",
            "Epoch 867/1200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 4794.9277 - val_loss: 23158.0273\n",
            "Epoch 868/1200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 4789.3584 - val_loss: 23128.4961\n",
            "Epoch 869/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4783.8115 - val_loss: 23099.0977\n",
            "Epoch 870/1200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 4778.2856 - val_loss: 23069.7324\n",
            "Epoch 871/1200\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 4772.7778 - val_loss: 23040.4980\n",
            "Epoch 872/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4767.2842 - val_loss: 23011.2988\n",
            "Epoch 873/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4761.8560 - val_loss: 22982.1289\n",
            "Epoch 874/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 4756.4644 - val_loss: 22953.0801\n",
            "Epoch 875/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 4751.0928 - val_loss: 22924.0488\n",
            "Epoch 876/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 4745.7363 - val_loss: 22895.1230\n",
            "Epoch 877/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4740.3979 - val_loss: 22866.2090\n",
            "Epoch 878/1200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 4735.0840 - val_loss: 22837.4199\n",
            "Epoch 879/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 4729.7905 - val_loss: 22808.6309\n",
            "Epoch 880/1200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 4724.5054 - val_loss: 22780.0176\n",
            "Epoch 881/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4719.2451 - val_loss: 22751.3789\n",
            "Epoch 882/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4713.9976 - val_loss: 22722.8848\n",
            "Epoch 883/1200\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 4708.7715 - val_loss: 22694.4434\n",
            "Epoch 884/1200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 4703.5605 - val_loss: 22666.0938\n",
            "Epoch 885/1200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 4698.3555 - val_loss: 22637.8086\n",
            "Epoch 886/1200\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 4693.1807 - val_loss: 22609.6621\n",
            "Epoch 887/1200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 4688.0195 - val_loss: 22581.5273\n",
            "Epoch 888/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4682.8706 - val_loss: 22553.4902\n",
            "Epoch 889/1200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 4677.7354 - val_loss: 22525.5293\n",
            "Epoch 890/1200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 4672.6187 - val_loss: 22497.7051\n",
            "Epoch 891/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 4667.5112 - val_loss: 22469.8750\n",
            "Epoch 892/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4662.4209 - val_loss: 22442.2188\n",
            "Epoch 893/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 4657.3486 - val_loss: 22414.5684\n",
            "Epoch 894/1200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 4652.2905 - val_loss: 22387.0488\n",
            "Epoch 895/1200\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 4647.2383 - val_loss: 22359.5801\n",
            "Epoch 896/1200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 4642.2085 - val_loss: 22332.2168\n",
            "Epoch 897/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4637.1846 - val_loss: 22304.9160\n",
            "Epoch 898/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4632.1816 - val_loss: 22277.6699\n",
            "Epoch 899/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4627.1846 - val_loss: 22250.5312\n",
            "Epoch 900/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4622.2021 - val_loss: 22223.4668\n",
            "Epoch 901/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4617.2363 - val_loss: 22196.4414\n",
            "Epoch 902/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4612.2817 - val_loss: 22169.4727\n",
            "Epoch 903/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4607.3335 - val_loss: 22142.6543\n",
            "Epoch 904/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4602.4023 - val_loss: 22115.8105\n",
            "Epoch 905/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 4597.4829 - val_loss: 22089.0840\n",
            "Epoch 906/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4592.5723 - val_loss: 22062.4219\n",
            "Epoch 907/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4587.6729 - val_loss: 22035.8438\n",
            "Epoch 908/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4582.7944 - val_loss: 22009.3184\n",
            "Epoch 909/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4577.9111 - val_loss: 21982.8496\n",
            "Epoch 910/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4573.0518 - val_loss: 21956.4160\n",
            "Epoch 911/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4568.1968 - val_loss: 21930.1250\n",
            "Epoch 912/1200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 4563.3545 - val_loss: 21903.8555\n",
            "Epoch 913/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4558.5254 - val_loss: 21877.6426\n",
            "Epoch 914/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4553.7046 - val_loss: 21851.5195\n",
            "Epoch 915/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4548.8955 - val_loss: 21825.4473\n",
            "Epoch 916/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4544.0928 - val_loss: 21799.4883\n",
            "Epoch 917/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4539.2998 - val_loss: 21773.5469\n",
            "Epoch 918/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4534.5200 - val_loss: 21747.6465\n",
            "Epoch 919/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4529.7495 - val_loss: 21721.8496\n",
            "Epoch 920/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4524.9873 - val_loss: 21696.1621\n",
            "Epoch 921/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4520.2354 - val_loss: 21670.4629\n",
            "Epoch 922/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4515.4937 - val_loss: 21644.8457\n",
            "Epoch 923/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4510.7578 - val_loss: 21619.3301\n",
            "Epoch 924/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4506.0298 - val_loss: 21593.8379\n",
            "Epoch 925/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4501.3135 - val_loss: 21568.4414\n",
            "Epoch 926/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4496.6055 - val_loss: 21543.0684\n",
            "Epoch 927/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4491.9014 - val_loss: 21517.8105\n",
            "Epoch 928/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4487.2124 - val_loss: 21492.5996\n",
            "Epoch 929/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 4482.5322 - val_loss: 21467.4551\n",
            "Epoch 930/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4477.8535 - val_loss: 21442.3848\n",
            "Epoch 931/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4473.1885 - val_loss: 21417.3438\n",
            "Epoch 932/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4468.5269 - val_loss: 21392.3711\n",
            "Epoch 933/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4463.8779 - val_loss: 21367.4570\n",
            "Epoch 934/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4459.2324 - val_loss: 21342.6543\n",
            "Epoch 935/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4454.5977 - val_loss: 21317.9102\n",
            "Epoch 936/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4449.9658 - val_loss: 21293.1621\n",
            "Epoch 937/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4445.3428 - val_loss: 21268.5645\n",
            "Epoch 938/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 4440.7354 - val_loss: 21244.0039\n",
            "Epoch 939/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4436.1182 - val_loss: 21219.4414\n",
            "Epoch 940/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4431.5244 - val_loss: 21195.0488\n",
            "Epoch 941/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4426.9287 - val_loss: 21170.6250\n",
            "Epoch 942/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4422.3374 - val_loss: 21146.3379\n",
            "Epoch 943/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4417.7578 - val_loss: 21122.0469\n",
            "Epoch 944/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4413.1846 - val_loss: 21097.8281\n",
            "Epoch 945/1200\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 4408.6123 - val_loss: 21073.6992\n",
            "Epoch 946/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4404.0503 - val_loss: 21049.6309\n",
            "Epoch 947/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4399.4937 - val_loss: 21025.5996\n",
            "Epoch 948/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4394.9692 - val_loss: 21001.5762\n",
            "Epoch 949/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4390.5117 - val_loss: 20977.6289\n",
            "Epoch 950/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4386.0547 - val_loss: 20953.7520\n",
            "Epoch 951/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4381.6123 - val_loss: 20929.8945\n",
            "Epoch 952/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4377.1743 - val_loss: 20906.1094\n",
            "Epoch 953/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4372.7490 - val_loss: 20882.3379\n",
            "Epoch 954/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4368.3232 - val_loss: 20858.6543\n",
            "Epoch 955/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4363.9155 - val_loss: 20834.9961\n",
            "Epoch 956/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4359.5088 - val_loss: 20811.4473\n",
            "Epoch 957/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4355.1123 - val_loss: 20787.8945\n",
            "Epoch 958/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4350.7217 - val_loss: 20764.4629\n",
            "Epoch 959/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4346.3325 - val_loss: 20741.1113\n",
            "Epoch 960/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4341.9521 - val_loss: 20717.8145\n",
            "Epoch 961/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4337.5840 - val_loss: 20694.5762\n",
            "Epoch 962/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4333.2080 - val_loss: 20671.4531\n",
            "Epoch 963/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4328.8579 - val_loss: 20648.3398\n",
            "Epoch 964/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4324.4976 - val_loss: 20625.3613\n",
            "Epoch 965/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4320.1499 - val_loss: 20602.4336\n",
            "Epoch 966/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4315.8042 - val_loss: 20579.5332\n",
            "Epoch 967/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4311.4658 - val_loss: 20556.7754\n",
            "Epoch 968/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4307.1318 - val_loss: 20534.0156\n",
            "Epoch 969/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4302.8008 - val_loss: 20511.3457\n",
            "Epoch 970/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4298.4756 - val_loss: 20488.8164\n",
            "Epoch 971/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4294.1577 - val_loss: 20466.2383\n",
            "Epoch 972/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4289.8408 - val_loss: 20443.7871\n",
            "Epoch 973/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4285.5298 - val_loss: 20421.4023\n",
            "Epoch 974/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4281.2231 - val_loss: 20399.0527\n",
            "Epoch 975/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4276.9180 - val_loss: 20376.8262\n",
            "Epoch 976/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4272.6152 - val_loss: 20354.6230\n",
            "Epoch 977/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4268.3271 - val_loss: 20332.4375\n",
            "Epoch 978/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4264.0303 - val_loss: 20310.3691\n",
            "Epoch 979/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4259.7471 - val_loss: 20288.2773\n",
            "Epoch 980/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 4255.4600 - val_loss: 20266.3613\n",
            "Epoch 981/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4251.1777 - val_loss: 20244.4434\n",
            "Epoch 982/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4246.9053 - val_loss: 20222.6074\n",
            "Epoch 983/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4242.6318 - val_loss: 20200.7715\n",
            "Epoch 984/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4238.3643 - val_loss: 20179.0273\n",
            "Epoch 985/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4234.0928 - val_loss: 20157.3242\n",
            "Epoch 986/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4229.8267 - val_loss: 20135.6816\n",
            "Epoch 987/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4225.5654 - val_loss: 20114.0996\n",
            "Epoch 988/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4221.3057 - val_loss: 20092.5801\n",
            "Epoch 989/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4217.0537 - val_loss: 20071.1973\n",
            "Epoch 990/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4212.7998 - val_loss: 20049.7852\n",
            "Epoch 991/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4208.5527 - val_loss: 20028.4160\n",
            "Epoch 992/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4204.2993 - val_loss: 20007.1445\n",
            "Epoch 993/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 4200.0518 - val_loss: 19985.9180\n",
            "Epoch 994/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4195.8091 - val_loss: 19964.7344\n",
            "Epoch 995/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4191.5703 - val_loss: 19943.6367\n",
            "Epoch 996/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4187.3350 - val_loss: 19922.6074\n",
            "Epoch 997/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4183.0977 - val_loss: 19901.6387\n",
            "Epoch 998/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4178.8555 - val_loss: 19880.7285\n",
            "Epoch 999/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4174.6216 - val_loss: 19859.8125\n",
            "Epoch 1000/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4170.3936 - val_loss: 19839.0195\n",
            "Epoch 1001/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4166.1602 - val_loss: 19818.3086\n",
            "Epoch 1002/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 4161.9331 - val_loss: 19797.6074\n",
            "Epoch 1003/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4157.7061 - val_loss: 19776.9668\n",
            "Epoch 1004/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4153.4795 - val_loss: 19756.3965\n",
            "Epoch 1005/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4149.2549 - val_loss: 19735.9199\n",
            "Epoch 1006/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4145.0356 - val_loss: 19715.4551\n",
            "Epoch 1007/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 4140.8096 - val_loss: 19695.0840\n",
            "Epoch 1008/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4136.5908 - val_loss: 19674.7500\n",
            "Epoch 1009/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 4132.3701 - val_loss: 19654.4648\n",
            "Epoch 1010/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4128.1548 - val_loss: 19634.2637\n",
            "Epoch 1011/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4123.9341 - val_loss: 19614.1309\n",
            "Epoch 1012/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4119.7168 - val_loss: 19594.0430\n",
            "Epoch 1013/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 4115.5039 - val_loss: 19574.0586\n",
            "Epoch 1014/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4111.2871 - val_loss: 19554.0566\n",
            "Epoch 1015/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4107.0684 - val_loss: 19534.1973\n",
            "Epoch 1016/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4102.8545 - val_loss: 19514.3281\n",
            "Epoch 1017/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4098.6436 - val_loss: 19494.5137\n",
            "Epoch 1018/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4094.4263 - val_loss: 19474.8184\n",
            "Epoch 1019/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4090.2134 - val_loss: 19455.1152\n",
            "Epoch 1020/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4086.0005 - val_loss: 19435.4707\n",
            "Epoch 1021/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4081.7839 - val_loss: 19415.9219\n",
            "Epoch 1022/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4077.5730 - val_loss: 19396.4590\n",
            "Epoch 1023/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4073.3608 - val_loss: 19376.9961\n",
            "Epoch 1024/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4069.1445 - val_loss: 19357.6250\n",
            "Epoch 1025/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4064.9297 - val_loss: 19338.2871\n",
            "Epoch 1026/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4060.7163 - val_loss: 19318.9980\n",
            "Epoch 1027/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4056.5044 - val_loss: 19299.8262\n",
            "Epoch 1028/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4052.2883 - val_loss: 19280.6504\n",
            "Epoch 1029/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4048.0698 - val_loss: 19261.5527\n",
            "Epoch 1030/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4043.8562 - val_loss: 19242.5137\n",
            "Epoch 1031/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 4039.6382 - val_loss: 19223.5273\n",
            "Epoch 1032/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4035.4204 - val_loss: 19204.6211\n",
            "Epoch 1033/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4031.2043 - val_loss: 19185.7676\n",
            "Epoch 1034/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 4026.9863 - val_loss: 19166.9629\n",
            "Epoch 1035/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4022.7656 - val_loss: 19148.2148\n",
            "Epoch 1036/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4018.5437 - val_loss: 19129.5898\n",
            "Epoch 1037/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4014.3184 - val_loss: 19110.9258\n",
            "Epoch 1038/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 4010.0950 - val_loss: 19092.3652\n",
            "Epoch 1039/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4005.8711 - val_loss: 19073.8418\n",
            "Epoch 1040/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 4001.6477 - val_loss: 19055.3770\n",
            "Epoch 1041/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3997.4219 - val_loss: 19036.9844\n",
            "Epoch 1042/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3993.1890 - val_loss: 19018.6504\n",
            "Epoch 1043/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3988.9602 - val_loss: 19000.3867\n",
            "Epoch 1044/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 3984.7266 - val_loss: 18982.1719\n",
            "Epoch 1045/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3980.4961 - val_loss: 18963.9863\n",
            "Epoch 1046/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3976.2610 - val_loss: 18945.8711\n",
            "Epoch 1047/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3972.0222 - val_loss: 18927.8184\n",
            "Epoch 1048/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3967.7832 - val_loss: 18909.8398\n",
            "Epoch 1049/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3963.5422 - val_loss: 18891.9434\n",
            "Epoch 1050/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3959.2993 - val_loss: 18874.0742\n",
            "Epoch 1051/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3955.0554 - val_loss: 18856.2402\n",
            "Epoch 1052/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3950.8071 - val_loss: 18838.4785\n",
            "Epoch 1053/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3946.5610 - val_loss: 18820.8145\n",
            "Epoch 1054/1200\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 3942.3074 - val_loss: 18803.1660\n",
            "Epoch 1055/1200\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 3938.0520 - val_loss: 18785.5977\n",
            "Epoch 1056/1200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 3933.7996 - val_loss: 18768.0723\n",
            "Epoch 1057/1200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 3929.5415 - val_loss: 18750.6035\n",
            "Epoch 1058/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3925.2817 - val_loss: 18733.2129\n",
            "Epoch 1059/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3921.0164 - val_loss: 18715.8535\n",
            "Epoch 1060/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3916.7495 - val_loss: 18698.5410\n",
            "Epoch 1061/1200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 3912.4797 - val_loss: 18681.2676\n",
            "Epoch 1062/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 3908.2144 - val_loss: 18664.1133\n",
            "Epoch 1063/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 3903.9348 - val_loss: 18647.0195\n",
            "Epoch 1064/1200\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 3899.6555 - val_loss: 18629.9160\n",
            "Epoch 1065/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 3895.3777 - val_loss: 18612.9609\n",
            "Epoch 1066/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 3891.0981 - val_loss: 18595.9863\n",
            "Epoch 1067/1200\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 3886.8110 - val_loss: 18579.1133\n",
            "Epoch 1068/1200\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 3882.5210 - val_loss: 18562.2695\n",
            "Epoch 1069/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3878.2312 - val_loss: 18545.5605\n",
            "Epoch 1070/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3873.9348 - val_loss: 18528.8027\n",
            "Epoch 1071/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 3869.6367 - val_loss: 18512.1484\n",
            "Epoch 1072/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3865.3340 - val_loss: 18495.5449\n",
            "Epoch 1073/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3861.0278 - val_loss: 18479.0332\n",
            "Epoch 1074/1200\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 3856.7222 - val_loss: 18462.5430\n",
            "Epoch 1075/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3852.4116 - val_loss: 18446.1055\n",
            "Epoch 1076/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 3848.0930 - val_loss: 18429.7441\n",
            "Epoch 1077/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3843.7720 - val_loss: 18413.4648\n",
            "Epoch 1078/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3839.4556 - val_loss: 18397.2188\n",
            "Epoch 1079/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3835.1265 - val_loss: 18380.9863\n",
            "Epoch 1080/1200\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 3830.7964 - val_loss: 18364.8398\n",
            "Epoch 1081/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3826.4661 - val_loss: 18348.7520\n",
            "Epoch 1082/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3822.1277 - val_loss: 18332.7480\n",
            "Epoch 1083/1200\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 3817.7878 - val_loss: 18316.8047\n",
            "Epoch 1084/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3813.4387 - val_loss: 18300.8887\n",
            "Epoch 1085/1200\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 3809.0950 - val_loss: 18285.0449\n",
            "Epoch 1086/1200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3804.7397 - val_loss: 18269.2305\n",
            "Epoch 1087/1200\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 3800.3835 - val_loss: 18253.5527\n",
            "Epoch 1088/1200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 3796.0249 - val_loss: 18237.8730\n",
            "Epoch 1089/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3791.6616 - val_loss: 18222.2617\n",
            "Epoch 1090/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3787.2896 - val_loss: 18206.6836\n",
            "Epoch 1091/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3782.9167 - val_loss: 18191.1719\n",
            "Epoch 1092/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3778.5425 - val_loss: 18175.7461\n",
            "Epoch 1093/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3774.1606 - val_loss: 18160.3672\n",
            "Epoch 1094/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3769.7808 - val_loss: 18145.0117\n",
            "Epoch 1095/1200\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 3765.3887 - val_loss: 18129.7949\n",
            "Epoch 1096/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3760.9966 - val_loss: 18114.5859\n",
            "Epoch 1097/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3756.5984 - val_loss: 18099.3926\n",
            "Epoch 1098/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3752.1968 - val_loss: 18084.3301\n",
            "Epoch 1099/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3747.7903 - val_loss: 18069.2715\n",
            "Epoch 1100/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3743.3809 - val_loss: 18054.3574\n",
            "Epoch 1101/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3738.9634 - val_loss: 18039.4141\n",
            "Epoch 1102/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3734.5449 - val_loss: 18024.5293\n",
            "Epoch 1103/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3730.1199 - val_loss: 18009.6973\n",
            "Epoch 1104/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3725.6929 - val_loss: 17994.9414\n",
            "Epoch 1105/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3721.2629 - val_loss: 17980.2500\n",
            "Epoch 1106/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3716.8247 - val_loss: 17965.5996\n",
            "Epoch 1107/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3712.3833 - val_loss: 17951.0605\n",
            "Epoch 1108/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3707.9351 - val_loss: 17936.5039\n",
            "Epoch 1109/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3703.4836 - val_loss: 17922.0449\n",
            "Epoch 1110/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3699.0293 - val_loss: 17907.6582\n",
            "Epoch 1111/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3694.5710 - val_loss: 17893.3398\n",
            "Epoch 1112/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3690.1011 - val_loss: 17879.0293\n",
            "Epoch 1113/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3685.6321 - val_loss: 17864.7656\n",
            "Epoch 1114/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3681.1614 - val_loss: 17850.6172\n",
            "Epoch 1115/1200\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3676.6824 - val_loss: 17836.4805\n",
            "Epoch 1116/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3672.1997 - val_loss: 17822.4023\n",
            "Epoch 1117/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3667.7124 - val_loss: 17808.4590\n",
            "Epoch 1118/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3663.2202 - val_loss: 17794.4980\n",
            "Epoch 1119/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3658.7234 - val_loss: 17780.5898\n",
            "Epoch 1120/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3654.2227 - val_loss: 17766.7910\n",
            "Epoch 1121/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3649.7168 - val_loss: 17753.0117\n",
            "Epoch 1122/1200\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 3645.2058 - val_loss: 17739.2910\n",
            "Epoch 1123/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3640.6929 - val_loss: 17725.6602\n",
            "Epoch 1124/1200\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3636.1707 - val_loss: 17712.0371\n",
            "Epoch 1125/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3631.6470 - val_loss: 17698.5312\n",
            "Epoch 1126/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3627.1191 - val_loss: 17685.0508\n",
            "Epoch 1127/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3622.5835 - val_loss: 17671.6074\n",
            "Epoch 1128/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3618.0500 - val_loss: 17658.2520\n",
            "Epoch 1129/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3613.5071 - val_loss: 17644.9766\n",
            "Epoch 1130/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3608.9604 - val_loss: 17631.7246\n",
            "Epoch 1131/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3604.4055 - val_loss: 17618.5254\n",
            "Epoch 1132/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3599.8496 - val_loss: 17605.3711\n",
            "Epoch 1133/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3595.2949 - val_loss: 17592.3164\n",
            "Epoch 1134/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3590.7253 - val_loss: 17579.2773\n",
            "Epoch 1135/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3586.1550 - val_loss: 17566.3379\n",
            "Epoch 1136/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3581.5847 - val_loss: 17553.4609\n",
            "Epoch 1137/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3577.0083 - val_loss: 17540.6152\n",
            "Epoch 1138/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3572.4272 - val_loss: 17527.8379\n",
            "Epoch 1139/1200\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3567.8374 - val_loss: 17515.0918\n",
            "Epoch 1140/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3563.2454 - val_loss: 17502.4375\n",
            "Epoch 1141/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3558.6528 - val_loss: 17489.8477\n",
            "Epoch 1142/1200\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3554.0562 - val_loss: 17477.3301\n",
            "Epoch 1143/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3549.4485 - val_loss: 17464.8379\n",
            "Epoch 1144/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3544.8423 - val_loss: 17452.4082\n",
            "Epoch 1145/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3540.2273 - val_loss: 17440.0352\n",
            "Epoch 1146/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3535.6138 - val_loss: 17427.6992\n",
            "Epoch 1147/1200\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3530.9941 - val_loss: 17415.4395\n",
            "Epoch 1148/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3526.3665 - val_loss: 17403.2637\n",
            "Epoch 1149/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3521.7429 - val_loss: 17391.1641\n",
            "Epoch 1150/1200\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3517.1086 - val_loss: 17379.0566\n",
            "Epoch 1151/1200\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3512.4780 - val_loss: 17367.0410\n",
            "Epoch 1152/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3507.8281 - val_loss: 17355.0625\n",
            "Epoch 1153/1200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3503.1914 - val_loss: 17343.1504\n",
            "Epoch 1154/1200\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3498.5457 - val_loss: 17331.3164\n",
            "Epoch 1155/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3493.8945 - val_loss: 17319.5254\n",
            "Epoch 1156/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3489.2395 - val_loss: 17307.7930\n",
            "Epoch 1157/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3484.5815 - val_loss: 17296.0957\n",
            "Epoch 1158/1200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3479.9199 - val_loss: 17284.5117\n",
            "Epoch 1159/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3475.2559 - val_loss: 17272.9512\n",
            "Epoch 1160/1200\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 3470.5864 - val_loss: 17261.4297\n",
            "Epoch 1161/1200\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3465.9116 - val_loss: 17250.0332\n",
            "Epoch 1162/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3461.2378 - val_loss: 17238.6230\n",
            "Epoch 1163/1200\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3456.5598 - val_loss: 17227.3105\n",
            "Epoch 1164/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3451.8801 - val_loss: 17216.0488\n",
            "Epoch 1165/1200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3447.1960 - val_loss: 17204.8145\n",
            "Epoch 1166/1200\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3442.5083 - val_loss: 17193.7148\n",
            "Epoch 1167/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3437.8157 - val_loss: 17182.6328\n",
            "Epoch 1168/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3433.1226 - val_loss: 17171.5996\n",
            "Epoch 1169/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3428.4243 - val_loss: 17160.6270\n",
            "Epoch 1170/1200\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3423.7231 - val_loss: 17149.6992\n",
            "Epoch 1171/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3419.0239 - val_loss: 17138.8477\n",
            "Epoch 1172/1200\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 3414.3159 - val_loss: 17128.0801\n",
            "Epoch 1173/1200\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3409.6106 - val_loss: 17117.3887\n",
            "Epoch 1174/1200\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3404.9019 - val_loss: 17106.7441\n",
            "Epoch 1175/1200\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 3400.1909 - val_loss: 17096.1211\n",
            "Epoch 1176/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3395.4753 - val_loss: 17085.5801\n",
            "Epoch 1177/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 3390.7559 - val_loss: 17075.1230\n",
            "Epoch 1178/1200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3386.0359 - val_loss: 17064.6680\n",
            "Epoch 1179/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3381.3176 - val_loss: 17054.3223\n",
            "Epoch 1180/1200\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3376.5930 - val_loss: 17044.0059\n",
            "Epoch 1181/1200\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 3371.8645 - val_loss: 17033.7031\n",
            "Epoch 1182/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3367.1406 - val_loss: 17023.5449\n",
            "Epoch 1183/1200\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3362.4087 - val_loss: 17013.4355\n",
            "Epoch 1184/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3357.6809 - val_loss: 17003.3906\n",
            "Epoch 1185/1200\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 3352.9429 - val_loss: 16993.3691\n",
            "Epoch 1186/1200\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 3348.2134 - val_loss: 16983.4277\n",
            "Epoch 1187/1200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 3343.4731 - val_loss: 16973.5371\n",
            "Epoch 1188/1200\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3338.7358 - val_loss: 16963.7168\n",
            "Epoch 1189/1200\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 3334.0007 - val_loss: 16953.9629\n",
            "Epoch 1190/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3329.2566 - val_loss: 16944.2773\n",
            "Epoch 1191/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3324.5168 - val_loss: 16934.6191\n",
            "Epoch 1192/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3319.7729 - val_loss: 16925.0645\n",
            "Epoch 1193/1200\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3315.0298 - val_loss: 16915.5137\n",
            "Epoch 1194/1200\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3310.2864 - val_loss: 16906.0918\n",
            "Epoch 1195/1200\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 3305.5442 - val_loss: 16896.6680\n",
            "Epoch 1196/1200\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3300.7944 - val_loss: 16887.3145\n",
            "Epoch 1197/1200\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3296.0476 - val_loss: 16878.0410\n",
            "Epoch 1198/1200\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 3291.3003 - val_loss: 16868.8086\n",
            "Epoch 1199/1200\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3286.5508 - val_loss: 16859.6602\n",
            "Epoch 1200/1200\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3281.8054 - val_loss: 16850.5215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD0Ol9Eq6soL",
        "outputId": "f8875dc1-c16f-48cb-bd56-b7dc715ce083"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 20908.1289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3IGySic2NNZ",
        "outputId": "af44a996-2f70-41f6-d5f6-b2a12113a993"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1l4qBVc3ayH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#预测\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred,y_test) #显示预测值和真实值"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iAdZKVz12YB",
        "outputId": "67b9a831-5783-48ac-a7ef-d8a600daac3e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 79ms/step\n",
            "[[ 261.4107  ]\n",
            " [1615.6826  ]\n",
            " [1068.7816  ]\n",
            " [1289.168   ]\n",
            " [ 701.12024 ]\n",
            " [ 412.4995  ]\n",
            " [1393.4384  ]\n",
            " [ 261.81674 ]\n",
            " [ 994.56506 ]\n",
            " [ 101.943054]] 14     420.98\n",
            "32    1653.45\n",
            "23     776.16\n",
            "28    1307.63\n",
            "20     602.00\n",
            "18     514.53\n",
            "30    1474.49\n",
            "8      260.69\n",
            "22     731.60\n",
            "4      118.31\n",
            "Name: agr_money, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mYwRhyk2-XH",
        "outputId": "c0e48867-7d32-4a07-93e1-691d28094acb"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 261.4107  ],\n",
              "       [1615.6826  ],\n",
              "       [1068.7816  ],\n",
              "       [1289.168   ],\n",
              "       [ 701.12024 ],\n",
              "       [ 412.4995  ],\n",
              "       [1393.4384  ],\n",
              "       [ 261.81674 ],\n",
              "       [ 994.56506 ],\n",
              "       [ 101.943054]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    }
  ]
}